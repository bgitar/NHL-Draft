{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Draft Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will build a classification model to predict future success of NHL draft prospects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#model imports\n",
    "from sklearn.model_selection import cross_val_score, KFold,train_test_split\n",
    "from sklearn.metrics import roc_auc_score, r2_score, confusion_matrix, accuracy_score, classification_report, precision_score, recall_score, f1_score, matthews_corrcoef, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "\n",
    "#logistic import\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "#random forest import\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#import xgboost as xgb\n",
    "#from xgboost import XGBRegressor\n",
    "\n",
    "#SMOTE\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#OLS\n",
    "#import statsmodels.formula.api as smf\n",
    "#import statsmodels.tools.eval_measures as smf_metrics\n",
    "\n",
    "#random forest import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#cross validaiton import\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df = pd.read_excel(\"C:/Users/BRG4142/Documents/hockey stuff/NHL Draft data/Model ready data/NHL_draft_clean_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OVERALL</th>\n",
       "      <th>NHL_TEAM</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POS2</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>DRAFT_YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>PS_PG</th>\n",
       "      <th>HT_CAT</th>\n",
       "      <th>HT_CAT2</th>\n",
       "      <th>GP_STANDARD</th>\n",
       "      <th>G_STANDARD</th>\n",
       "      <th>A_STANDARD</th>\n",
       "      <th>PTS_STANDARD</th>\n",
       "      <th>GPG_STANDARD</th>\n",
       "      <th>APG_STANDARD</th>\n",
       "      <th>PPG_STANDARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Edmonton Oilers</td>\n",
       "      <td>Taylor Hall</td>\n",
       "      <td>18</td>\n",
       "      <td>74.2</td>\n",
       "      <td>2010</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>6.01</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.393029</td>\n",
       "      <td>2.531579</td>\n",
       "      <td>3.548666</td>\n",
       "      <td>3.365403</td>\n",
       "      <td>2.945029</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>3.798937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>Tyler Seguin</td>\n",
       "      <td>18</td>\n",
       "      <td>84.4</td>\n",
       "      <td>2010</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102303</td>\n",
       "      <td>6.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>3.373684</td>\n",
       "      <td>2.920722</td>\n",
       "      <td>3.365403</td>\n",
       "      <td>3.346032</td>\n",
       "      <td>2.764928</td>\n",
       "      <td>3.262241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>Erik Gudbranson</td>\n",
       "      <td>18</td>\n",
       "      <td>16.6</td>\n",
       "      <td>2010</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025897</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.011481</td>\n",
       "      <td>-0.686420</td>\n",
       "      <td>0.270814</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>-0.520325</td>\n",
       "      <td>1.286031</td>\n",
       "      <td>0.852265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Columbus Blue Jackets</td>\n",
       "      <td>Ryan Johansen</td>\n",
       "      <td>18</td>\n",
       "      <td>52.3</td>\n",
       "      <td>2010</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066455</td>\n",
       "      <td>6.02</td>\n",
       "      <td>4</td>\n",
       "      <td>1.044803</td>\n",
       "      <td>1.279395</td>\n",
       "      <td>1.931174</td>\n",
       "      <td>1.761375</td>\n",
       "      <td>0.818341</td>\n",
       "      <td>1.495820</td>\n",
       "      <td>1.339437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>New York Islanders</td>\n",
       "      <td>Nino Niederreiter</td>\n",
       "      <td>18</td>\n",
       "      <td>42.8</td>\n",
       "      <td>2010</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>6.02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.507168</td>\n",
       "      <td>2.559953</td>\n",
       "      <td>0.311741</td>\n",
       "      <td>1.306370</td>\n",
       "      <td>2.290848</td>\n",
       "      <td>0.156314</td>\n",
       "      <td>1.176923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  OVERALL               NHL_TEAM             PLAYER  AGE    PS  \\\n",
       "0           0        1        Edmonton Oilers        Taylor Hall   18  74.2   \n",
       "1           1        2          Boston Bruins       Tyler Seguin   18  84.4   \n",
       "2           2        3       Florida Panthers    Erik Gudbranson   18  16.6   \n",
       "3           3        4  Columbus Blue Jackets      Ryan Johansen   18  52.3   \n",
       "4           4        5     New York Islanders  Nino Niederreiter   18  42.8   \n",
       "\n",
       "   YEAR POS2  ROUND  DRAFT_YEAR  ...     PS_PG  HT_CAT  HT_CAT2  GP_STANDARD  \\\n",
       "0  2010    W      1        2010  ...  0.097503    6.01        3    -0.393029   \n",
       "1  2010    C      1        2010  ...  0.102303    6.01        3     0.328125   \n",
       "2  2010    D      1        2010  ...  0.025897    6.04        5    -2.011481   \n",
       "3  2010    C      1        2010  ...  0.066455    6.02        4     1.044803   \n",
       "4  2010    W      1        2010  ...  0.058470    6.02        4     0.507168   \n",
       "\n",
       "   G_STANDARD  A_STANDARD PTS_STANDARD  GPG_STANDARD  APG_STANDARD  \\\n",
       "0    2.531579    3.548666     3.365403      2.945029      3.894737   \n",
       "1    3.373684    2.920722     3.365403      3.346032      2.764928   \n",
       "2   -0.686420    0.270814     0.012775     -0.520325      1.286031   \n",
       "3    1.279395    1.931174     1.761375      0.818341      1.495820   \n",
       "4    2.559953    0.311741     1.306370      2.290848      0.156314   \n",
       "\n",
       "   PPG_STANDARD  \n",
       "0      3.798937  \n",
       "1      3.262241  \n",
       "2      0.852265  \n",
       "3      1.339437  \n",
       "4      1.176923  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 35)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.537489\n",
       "0    0.462511\n",
       "Name: REACH_NHL, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine target\n",
    "df['REACH_NHL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.711036\n",
       "1    0.288964\n",
       "Name: NHL_REGULAR, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NHL_REGULAR'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop if age > 18\n",
    "df= df[(df['AGE'] <= 18) & (df['POS2'] != 'D')] #forwards\n",
    "#df= df[(df['AGE'] <= 18) & (df['POS2'] == 'D')] #defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get categories\n",
    "df['POS2'] = df['POS2'].astype('category').cat.codes\n",
    "#df['AGE'] = df['AGE'].astype('category').cat.codes\n",
    "df['HT_CAT'] = df['HT_CAT'].astype('category').cat.codes\n",
    "df['LGE_CAT'] = df['LGE2'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "X = df[[\n",
    "    'PLAYER',\n",
    "    'LGE2',\n",
    "    'PRO_LEAGUE',\n",
    "    'ROUND',\n",
    "    'OVERALL',\n",
    "    'PS',\n",
    "    'POS2', \n",
    "    'HT_CAT', \n",
    "    'LGE_CAT', \n",
    "    'GP_STANDARD', \n",
    "    'G_STANDARD', \n",
    "    'A_STANDARD',\n",
    "    'PTS_STANDARD',\n",
    "    'GPG_STANDARD', \n",
    "    'APG_STANDARD',\n",
    "    'PPG_STANDARD'\n",
    "        ]]\n",
    "\n",
    "\n",
    "#y= df['REACH_NHL'] #reach nhl target\n",
    "y= df['NHL_REGULAR'] #nhl regular target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_output, X_test_output, y_train, y_test = train_test_split(X, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_output[['POS2', \n",
    "        'HT_CAT', \n",
    "        'LGE_CAT',\n",
    "        #'PRO_LEAGUE',\n",
    "        #'GP_STANDARD', \n",
    "        'G_STANDARD', \n",
    "        'A_STANDARD',\n",
    "        'PTS_STANDARD',\n",
    "        'GPG_STANDARD', \n",
    "        'APG_STANDARD',\n",
    "        'PPG_STANDARD']]\n",
    "\n",
    "X_test = X_test_output[['POS2', \n",
    "        'HT_CAT', \n",
    "        'LGE_CAT', \n",
    "        #'PRO_LEAGUE',\n",
    "        #'GP_STANDARD', \n",
    "        'G_STANDARD', \n",
    "        'A_STANDARD',\n",
    "        'PTS_STANDARD',\n",
    "        'GPG_STANDARD', \n",
    "        'APG_STANDARD',\n",
    "        'PPG_STANDARD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=9)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=99)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=1, random_state=99)\n",
    "\n",
    "#Fit your model on the features (X) and the target (y)\n",
    "model.fit(X_train, y_train)\n",
    "#model.fit(X_res, y_res) #smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.664\n",
      "AUC 0.695\n",
      "[[79 17]\n",
      " [34 22]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) #returns 0 or 1\n",
    "pred_proba = model.predict_proba(X_test)[:,1] # returns predicted probabilites \n",
    "print(\"Accuracy\", accuracy_score(y_test, y_pred).round(3))\n",
    "print(\"AUC\", roc_auc_score(y_test, pred_proba).round(3))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is Random Forest classifier\n",
      "The accuracy is  0.664\n",
      "The precision is 0.564\n",
      "The recall is 0.393\n",
      "The F1-Score is 0.463\n"
     ]
    }
   ],
   "source": [
    "#print out accuracy measures\n",
    "print(\"The model used is Random Forest classifier\")\n",
    "acc= accuracy_score(y_test,y_pred).round(3)\n",
    "print(\"The accuracy is  {}\".format(acc))\n",
    "prec= precision_score(y_test,y_pred).round(3)\n",
    "print(\"The precision is {}\".format(prec))\n",
    "rec= recall_score(y_test,y_pred).round(3)\n",
    "print(\"The recall is {}\".format(rec))\n",
    "f1= f1_score(y_test,y_pred).round(3)\n",
    "print(\"The F1-Score is {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTS_STANDARD    0.153481\n",
       "PPG_STANDARD    0.153237\n",
       "A_STANDARD      0.151437\n",
       "APG_STANDARD    0.135522\n",
       "G_STANDARD      0.134590\n",
       "GPG_STANDARD    0.128211\n",
       "LGE_CAT         0.084304\n",
       "HT_CAT          0.059216\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature importance\n",
    "feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search\n",
    "#print('Processing GridSearch. Please hold for the next available set of outputs.\\n')\n",
    "#parameters = {\"max_depth\": [5,10,15,20,25]\n",
    "#             ,\"min_samples_split\" :[2,3,4]\n",
    "#             ,\"n_estimators\" : [10, 20, 50, 100]\n",
    "#             ,\"min_samples_leaf\": [1,2,3]\n",
    "#             ,\"criterion\": ('gini','entropy')}\n",
    "\n",
    "#rf = RandomForestClassifier(random_state=99)\n",
    "#gd_model = GridSearchCV(rf, parameters, n_jobs = -1, cv=5)\n",
    "#gd_model.fit(X_train,y_train)\n",
    "\n",
    "#print(gd_model.best_params_)\n",
    "#print(gd_model.best_estimator_)\n",
    "#print(gd_model.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Processing GridSearch. Please hold for the next available set of outputs.\n",
    "\n",
    "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
    "RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=4,\n",
    "                       random_state=99)\n",
    "0.6235955056179774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BRG4142\\.conda\\envs\\virtual_conda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.07, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=1, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=1, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "#xgb_model = XGBClassifier()\n",
    "\n",
    "#tune parameters\n",
    "xgb_model = XGBClassifier(\n",
    " learning_rate =0.07,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=1)\n",
    "\n",
    "#xgb_model.fit(X_train, y_train) \n",
    "xgb_model.fit(X_res, y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.612\n",
      "AUC 0.643\n",
      "[[65 31]\n",
      " [28 28]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy_xgb = accuracy_score(y_test, predictions)\n",
    "pred_proba_xgb = xgb_model.predict_proba(X_test)[:,1] # returns predicted probabilites\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Accuracy\", accuracy_score(y_test, predictions).round(3))\n",
    "print(\"AUC\", roc_auc_score(y_test, pred_proba_xgb).round(3))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is XGBoost\n",
      "The accuracy is  0.612\n",
      "The precision is 0.475\n",
      "The recall is 0.5\n",
      "The F1-Score is 0.487\n"
     ]
    }
   ],
   "source": [
    "#print out accuracy measures\n",
    "print(\"The model used is XGBoost\")\n",
    "acc= accuracy_score(y_test,y_pred_xgb).round(3)\n",
    "print(\"The accuracy is  {}\".format(acc))\n",
    "prec= precision_score(y_test,y_pred_xgb).round(3)\n",
    "print(\"The precision is {}\".format(prec))\n",
    "rec= recall_score(y_test,y_pred_xgb).round(3)\n",
    "print(\"The recall is {}\".format(rec))\n",
    "f1= f1_score(y_test,y_pred_xgb).round(3)\n",
    "print(\"The F1-Score is {}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append test dataset, target from test dataset, and predicted probabilty of finding together\n",
    "df_pred = pd.DataFrame(X_test_output)\n",
    "df_pred['Target'] = y_test\n",
    "df_pred['Probability'] = pred_proba[:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to excel\n",
    "df_pred.to_excel(\"C:/Users/BRG4142/Documents/hockey stuff/NHL Draft data/Model ready data/NHL_REGULAR_model_predictions.xlsx\",\n",
    "             sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Conda",
   "language": "python",
   "name": "virtual_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
